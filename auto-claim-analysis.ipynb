{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":110281,"databundleVersionId":13391012,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install google-cloud-bigquery[bqstorage]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================================================================\n# DUAL-PATH BIGQUERY CONNECTION FOR KAGGLE NOTEBOOKS\n# -------------------------------------------------------------------\n# This cell creates a robust connection that works in two modes:\n# 1. EDITOR MODE: If Kaggle Secrets are available, it uses them for\n#    private, authenticated access.\n# 2. PUBLIC MODE: If secrets are NOT found, it falls back to public\n#    authentication, which works for judges and public viewers if the\n#    dataset is public.\n# ===================================================================\n\n# --- Step 1: Necessary Imports ---\nimport os\nfrom google.colab import auth\nfrom google.cloud import bigquery\nimport bigframes.pandas as bf\nfrom kaggle_secrets import UserSecretsClient\n\n# --- Step 2: Define Project Constants ---\nproject_id = \"bqhackathonautoianalysis\"\nlocation = \"us-central1\"\n\n# --- Step 3: Clean up any previous BigFrames session ---\n# This prevents hanging issues on re-runs.\ntry:\n    bf.close_session()\nexcept Exception:\n    pass\n\n# --- Step 4: Attempt Authentication ---\nprint(\"Attempting to connect to BigQuery...\")\nclient = None\nauth_method = \"Unknown\"\n\ntry:\n    # --- PATH 1: EDITOR MODE (using Kaggle Secrets) ---\n    print(\"  -> Trying Editor Mode (using Kaggle Secrets)...\")\n    \n    user_secrets = UserSecretsClient()\n    service_account_info = user_secrets.get_secret(\"GOOGLE_APPLICATION_CREDENTIALS\")\n    \n    # Write the secret to a temporary file\n    with open('/tmp/service-account-key.json', 'w') as f:\n        f.write(service_account_info)\n    \n    # Set the environment variable for automatic authentication\n    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/tmp/service-account-key.json'\n    \n    # Initialize clients (they will automatically use the environment variable)\n    client = bigquery.Client(project=project_id)\n    bf.options.bigquery.project = project_id\n    bf.options.bigquery.location = location\n    \n    auth_method = \"Kaggle Secrets\"\n    print(\"‚úÖ Successfully connected using Editor Mode (Kaggle Secrets).\")\n\nexcept Exception:\n    # --- PATH 2: PUBLIC MODE (using default authentication) ---\n    print(\"  -> Kaggle Secrets not found. Falling back to Public Mode...\")\n    \n    try:\n        # Authenticate the user for the session (triggers pop-up for owner, automatic for public)\n        auth.authenticate_user()\n        \n        # Explicitly get the credentials to pass to the clients\n        credentials, _ = auth.default()\n\n        client = bigquery.Client(project=project_id, credentials=credentials)\n        bf.options.bigquery.project = project_id\n        bf.options.bigquery.location = location\n        bf.options.bigquery.credentials = credentials\n        \n        auth_method = \"Public Authentication\"\n        print(\"‚úÖ Successfully connected using Public Mode.\")\n        \n    except Exception as e:\n        print(f\"‚ùå Public authentication also failed. Error: {e}\")\n        auth_method = \"Failed\"\n\n# --- Step 5: Final Connection Test ---\nif client:\n    try:\n        test_query = f\"SELECT COUNT(*) as total_rows FROM `{project_id}.autoAnalysis_Dataset.Claims`\"\n        result = client.query(test_query).to_dataframe()\n        print(\"\\n---------------------------------------------------------\")\n        print(f\"üéâ SUCCESS! Connection established via '{auth_method}'.\")\n        print(f\"Total rows in the Claims table: {result['total_rows'].iloc[0]}\")\n        print(\"---------------------------------------------------------\")\n    except Exception as e:\n        print(f\"‚ùå Connection test failed after authenticating via '{auth_method}'.\")\n        print(f\"   Error: {e}\")\nelse:\n    print(\"\\n‚ùå Could not establish a BigQuery client.\")\n    print(\"\\nTroubleshooting:\")\n    print(\"  - For Editors: Ensure your Kaggle secret is named 'GOOGLE_APPLICATION_CREDENTIALS'.\")\n    print(\"  - For Public Users/Judges: The dataset 'bqhackathonautoianalysis.autoAnalysis_Dataset' must be made public.\")\n\n# ===================================================================","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\nprint(\"Step 1 complete. Now RESTART the kernel (Runtime -> Restart Runtime)\")\nprint(\"Then run Cell 2 below.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Try secret key\n# # ===================================================================\n# # UNIVERSAL BIGQUERY CONNECTION FOR PUBLIC DATASET\n# # This method works for anyone running this public notebook.\n# # It assumes the 'bqhackathonautoianalysis' project has its \n# # 'autoAnalysis_Dataset' set to public (with 'allUsers' having the \n# # 'BigQuery Data Viewer' role).\n# # ===================================================================\n\n# from google.cloud import bigquery\n# import bigframes.pandas as bf\n\n# # The project ID where the public data resides\n# project_id = \"bqhackathonautoianalysis\" \n# location = \"us-central1\" # Specify your dataset's location for BigFrames\n\n# try:\n#     # --- Initialize clients for google-cloud-bigquery and BigFrames ---\n    \n#     # Initialize the standard BigQuery client\n#     client = bigquery.Client(project=project_id)\n    \n#     # Initialize the BigFrames session, which also handles authentication\n#     bf.options.bigquery.project = project_id\n#     bf.options.bigquery.location = location\n    \n#     # --- Test Connection ---\n#     test_query = f\"\"\"\n#     SELECT COUNT(*) as total_rows \n#     FROM `{project_id}.autoAnalysis_Dataset.Claims`\n#     LIMIT 1\n#     \"\"\"\n    \n#     result = client.query(test_query).to_dataframe()\n#     print(f\"üéâ SUCCESS! Connected to public dataset.\")\n#     print(f\"Total rows in the public Claims table: {result['total_rows'].iloc[0]}\")\n    \n#     print(\"\\n‚úÖ You can now run your queries using the 'client' object for standard BigQuery...\")\n#     print(\"   Example: client.query(your_sql).to_dataframe()\")\n    \n#     print(\"\\n‚úÖ ...and use BigFrames functions for large-scale data manipulation.\")\n#     print(\"   Example: bf.read_gbq('bqhackathonautoianalysis.autoAnalysis_Dataset.Claims')\")\n\n# except Exception as e:\n#     print(f\"‚ùå BigQuery connection failed.\")\n#     print(f\"   Error: {e}\")\n#     print(\"\\nTroubleshooting:\")\n#     print(\"1. Ensure this notebook has internet access enabled in Kaggle settings.\")\n#     print(\"2. Verify that the 'bqhackathonautoianalysis.autoAnalysis_Dataset' is public.\")\n#     print(\"   - Go to the Google Cloud Console.\")\n#     print(\"   - Share the dataset and add the principal 'allUsers' with the role 'BigQuery Data Viewer'.\")\n\n# # ===================================================================","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"secret key !!","metadata":{}},{"cell_type":"code","source":"# !pip install --upgrade google-cloud-bigquery==3.31.0\n# !pip install rich==13.7.1\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================================================================\n# DUAL-PATH BIGQUERY CONNECTION FOR KAGGLE NOTEBOOKS\n# -------------------------------------------------------------------\n# This cell creates a robust connection that works in two modes:\n# 1. EDITOR MODE: If Kaggle Secrets are available, it uses them for\n#    private, authenticated access.\n# 2. PUBLIC MODE: If secrets are NOT found, it falls back to public\n#    authentication, which works for judges and public viewers if the\n#    dataset is public.\n# ===================================================================\n\n# --- Step 1: Necessary Imports ---\nimport os\nfrom google.colab import auth\nfrom google.cloud import bigquery\nimport bigframes.pandas as bf\nfrom kaggle_secrets import UserSecretsClient\n\n# --- Step 2: Define Project Constants ---\nproject_id = \"bqhackathonautoianalysis\"\nlocation = \"us-central1\"\n\n# --- Step 3: Clean up any previous BigFrames session ---\n# This prevents hanging issues on re-runs.\ntry:\n    bf.close_session()\nexcept Exception:\n    pass\n\n# --- Step 4: Attempt Authentication ---\nprint(\"Attempting to connect to BigQuery...\")\nclient = None\nauth_method = \"Unknown\"\n\ntry:\n    # --- PATH 1: EDITOR MODE (using Kaggle Secrets) ---\n    print(\"  -> Trying Editor Mode (using Kaggle Secrets)...\")\n    \n    user_secrets = UserSecretsClient()\n    service_account_info = user_secrets.get_secret(\"GOOGLE_APPLICATION_CREDENTIALS\")\n    \n    # Write the secret to a temporary file\n    with open('/tmp/service-account-key.json', 'w') as f:\n        f.write(service_account_info)\n    \n    # Set the environment variable for automatic authentication\n    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/tmp/service-account-key.json'\n    \n    # Initialize clients (they will automatically use the environment variable)\n    client = bigquery.Client(project=project_id)\n    bf.options.bigquery.project = project_id\n    bf.options.bigquery.location = location\n    \n    auth_method = \"Kaggle Secrets\"\n    print(\"‚úÖ Successfully connected using Editor Mode (Kaggle Secrets).\")\n\nexcept Exception:\n    # --- PATH 2: PUBLIC MODE (using default authentication) ---\n    print(\"  -> Kaggle Secrets not found. Falling back to Public Mode...\")\n    \n    try:\n        # Authenticate the user for the session (triggers pop-up for owner, automatic for public)\n        auth.authenticate_user()\n        \n        # Explicitly get the credentials to pass to the clients\n        credentials, _ = auth.default()\n\n        client = bigquery.Client(project=project_id, credentials=credentials)\n        bf.options.bigquery.project = project_id\n        bf.options.bigquery.location = location\n        bf.options.bigquery.credentials = credentials\n        \n        auth_method = \"Public Authentication\"\n        print(\"‚úÖ Successfully connected using Public Mode.\")\n        \n    except Exception as e:\n        print(f\"‚ùå Public authentication also failed. Error: {e}\")\n        auth_method = \"Failed\"\n\n# --- Step 5: Final Connection Test ---\nif client:\n    try:\n        test_query = f\"SELECT COUNT(*) as total_rows FROM `{project_id}.autoAnalysis_Dataset.Claims`\"\n        result = client.query(test_query).to_dataframe()\n        print(\"\\n---------------------------------------------------------\")\n        print(f\"üéâ SUCCESS! Connection established via '{auth_method}'.\")\n        print(f\"Total rows in the Claims table: {result['total_rows'].iloc[0]}\")\n        print(\"---------------------------------------------------------\")\n    except Exception as e:\n        print(f\"‚ùå Connection test failed after authenticating via '{auth_method}'.\")\n        print(f\"   Error: {e}\")\nelse:\n    print(\"\\n‚ùå Could not establish a BigQuery client.\")\n    print(\"\\nTroubleshooting:\")\n    print(\"  - For Editors: Ensure your Kaggle secret is named 'GOOGLE_APPLICATION_CREDENTIALS'.\")\n    print(\"  - For Public Users/Judges: The dataset 'bqhackathonautoianalysis.autoAnalysis_Dataset' must be made public.\")\n\n# ===================================================================","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sql = \"\"\"\nSELECT * FROM `bqhackathonautoianalysis.autoAnalysis_Dataset.Policies` \n\"\"\"\ndf = client.query(sql).to_dataframe()\ndf","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"List of all the tables in DB.","metadata":{}},{"cell_type":"code","source":"# Query 2: List all tables in the dataset\nquery_tables = \"\"\"\nSELECT table_name\nFROM `bqhackathonautoianalysis.autoAnalysis_Dataset.INFORMATION_SCHEMA.TABLES`\nORDER BY table_name\n\"\"\"\ndf_tables = client.query(query_tables).to_dataframe()\nprint(df_tables)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.cloud import bigquery\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Initialize BigQuery client\nproject_id = \"bqhackathonautoianalysis\"\nbq_client = bigquery.Client(project=project_id)\n\n# Define table names\ntables = {\n    \"Image Claims\": \"Image_Claims_Analysis\",\n    \"Vehicles\": \"Vehicles\", \n    \"Claims\": \"Claims\",\n    \"Policies\": \"Policies\",\n    \"Policyholders\": \"Policyholders\"\n}\n\ndef clean_dataframe_simple(df):\n    \"\"\"Simple cleaning without fillna - just handle infinities\"\"\"\n    # Replace infinite values with NaN (but don't fill)\n    df.replace([float('inf'), float('-inf')], np.nan, inplace=True)\n    return df\n\n# Alternative: Query with explicit handling in SQL\ndef get_table_with_coalesce(table_name):\n    \"\"\"Get table data with SQL-level null handling\"\"\"\n    full_table = f\"{project_id}.autoAnalysis_Dataset.{table_name}\"\n    \n    # First, get column info\n    info_query = f\"\"\"\n    SELECT column_name, data_type \n    FROM `{project_id}.autoAnalysis_Dataset.INFORMATION_SCHEMA.COLUMNS` \n    WHERE table_name = '{table_name}'\n    \"\"\"\n    \n    try:\n        col_info = bq_client.query(info_query).to_dataframe()\n        \n        # Build select statement with appropriate defaults\n        select_parts = []\n        for _, row in col_info.iterrows():\n            col_name = row['column_name']\n            data_type = row['data_type'].upper()\n            \n            if 'BOOL' in data_type:\n                select_parts.append(f\"COALESCE({col_name}, FALSE) as {col_name}\")\n            elif any(x in data_type for x in ['INT', 'FLOAT', 'NUMERIC']):\n                select_parts.append(f\"COALESCE({col_name}, 0) as {col_name}\")\n            elif 'STRING' in data_type:\n                select_parts.append(f\"COALESCE({col_name}, '') as {col_name}\")\n            else:\n                select_parts.append(col_name)  # Leave as is\n        \n        query = f\"SELECT {', '.join(select_parts)} FROM `{full_table}`\"\n        return bq_client.query(query).to_dataframe()\n        \n    except Exception as e:\n        print(f\"Could not get column info for {table_name}: {e}\")\n        # Fallback to simple query\n        query = f\"SELECT * FROM `{full_table}`\"\n        return bq_client.query(query).to_dataframe()\n\n# Query and display each table\nfor name, table in tables.items():\n    print(f\"\\n=== {name.upper()} ===\")\n    \n    try:\n        # Try the SQL-level approach first\n        df = get_table_with_coalesce(table)\n        \n        # Simple cleaning\n        df = clean_dataframe_simple(df)\n        \n        print(f\"Successfully loaded {name}\")\n        display(df.head())\n        print(f\"Shape: {df.shape}\")\n        print(f\"Data types:\")\n        print(df.dtypes)\n        print(f\"Null values per column:\")\n        print(df.isnull().sum())\n        \n    except Exception as e:\n        print(f\"Error loading {name}: {e}\")\n        \n        # Try simple fallback approach\n        try:\n            full_table = f\"{project_id}.autoAnalysis_Dataset.{table}\"\n            query = f\"SELECT * FROM `{full_table}`\"\n            df = bq_client.query(query).to_dataframe()\n            \n            print(f\"Fallback successful for {name} (with null values)\")\n            display(df.head())\n            print(f\"Shape: {df.shape}\")\n            print(f\"Null values per column:\")\n            print(df.isnull().sum())\n            \n        except Exception as e2:\n            print(f\"Complete failure for {name}: {e2}\")\n            continue","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Table Overview & Join Keys","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nproject_id = \"bqhackathonautoianalysis\"\nbq_client = bigquery.Client(project=project_id)\n# List of tables and expected join keys\ntables = {\n    \"Claims\": \"Claims\",\n    \"Image_Claims_Analysis\": \"Image_Claims_Analysis\",\n    \"Vehicles\": \"Vehicles\",\n    \"Policies\": \"Policies\",\n    \"Policyholders\": \"Policyholders\"\n}\n\n# Display schema for each table\nfor name, table in tables.items():\n    query = f\"\"\"\n    SELECT column_name, data_type, is_nullable\n    FROM `{project_id}.autoAnalysis_Dataset.INFORMATION_SCHEMA.COLUMNS`\n    WHERE table_name = '{table}'\n    ORDER BY column_name\n    \"\"\"\n    schema_df = bq_client.query(query).to_dataframe()\n    print(f\"\\n=== {name.upper()} SCHEMA ===\")\n    display(schema_df)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Basic Column Profiling","metadata":{}},{"cell_type":"code","source":"# Load each table into a DataFrame\ndfs = {}\nfor name, table in tables.items():\n    query = f\"SELECT * FROM `{project_id}.autoAnalysis_Dataset.{table}`\"\n    df = bq_client.query(query).to_dataframe()\n    dfs[name] = df\n\n# Profile each table\nfor name, df in dfs.items():\n    print(f\"\\n=== {name.upper()} ===\")\n    display(df.head())\n    print(df.info())\n    print(\"Missing values:\\n\", df.isnull().sum())\n    print(\"Unique values:\\n\", df.nunique())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Distribution Analysis","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# --- Distribution Analysis (Presentation Ready) ---\n# This cell provides a polished visual analysis of key data distributions\n# for the final submission notebook.\n# ==============================================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Set a professional plot style for all subsequent charts in the notebook\nsns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n\n# --- Analysis 1: Accident Type Distribution ---\n\n# Get the data and prepare it for display\ndf_claims = dfs[\"Claims\"]\naccident_counts = df_claims[\"accident_type\"].value_counts()\n\n# -- Output 1.1: Beautified Table --\nprint(\"Accident Type Distribution (Table View)\")\ndisplay(accident_counts.to_frame(name=\"Number of Claims\").style\n    .set_caption(\"Frequency of Each Accident Type\")\n    .set_table_styles([\n        {'selector': 'th', 'props': [('background-color', '#440154'), ('color', 'white'), ('font-weight', 'bold')]},\n        {'selector': 'caption', 'props': [('color', '#440154'), ('font-size', '1.1em'), ('font-weight', 'bold')]}\n    ])\n    .bar(color='#40B7AD', vmin=0)\n)\n\n# -- Output 1.2: Beautified Bar Chart --\nplt.figure(figsize=(12, 8))\nax = sns.countplot(\n    data=df_claims,\n    y='accident_type',\n    order=accident_counts.index  # Sort bars from most to least frequent\n)\n\n# Add clear data labels to the end of each bar\nax.bar_label(ax.containers[0], padding=5, fontsize=11, fontweight='bold')\n\n# Set well-defined titles and labels\nax.set_title('Distribution of Accident Types', fontsize=16, fontweight='bold')\nax.set_xlabel('Number of Claims', fontsize=12)\nax.set_ylabel('Accident Type', fontsize=12)\nax.set_xlim(right=accident_counts.max() * 1.15) # Add padding for labels\n\nprint(\"\\n\\nAccident Type Distribution (Chart View)\")\nplt.tight_layout()\nplt.show()\n\n\n# --- Analysis 2: Vehicle Age Distribution ---\n\n# Get the data\ndf_vehicles = dfs[\"Vehicles\"]\n\n# -- Output 2.1: Beautified Histogram --\nplt.figure(figsize=(10, 6))\nax = sns.histplot(\n    data=df_vehicles,\n    x='vehicle_age',\n    bins=25,          # Adjusted for better granularity\n    kde=True,         # Adds a smooth density curve\n    color=\"#21918c\"\n)\n\n# Add a vertical line for the mean age for context\nmean_age = df_vehicles['vehicle_age'].mean()\nax.axvline(mean_age, color='#fde725', linestyle='--', linewidth=2.5, label=f'Mean Age: {mean_age:.1f} years')\n\n# Set well-defined titles and labels\nax.set_title('Distribution of Vehicle Ages', fontsize=16, fontweight='bold')\nax.set_xlabel('Vehicle Age (Years)', fontsize=12)\nax.set_ylabel('Frequency (Number of Vehicles)', fontsize=12)\nax.legend() # Display the label for the mean line\n\nprint(\"\\n\\nVehicle Age Distribution\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Join Coverage","metadata":{}},{"cell_type":"code","source":"# Reload Claims table to get the updated schema with vin column\nquery = \"SELECT * FROM `bqhackathonautoianalysis.autoAnalysis_Dataset.Claims`\"\ndf_claims = client.query(query).to_dataframe()\n\n# Verify the vin column is now available\nprint(\"Updated Claims table columns:\")\nprint(df_claims.columns.tolist())\n\n# Check if vin column exists\nif 'vin' in df_claims.columns:\n    print(\"‚úÖ vin column now exists in Claims DataFrame\")\n    print(\"Sample vin values:\", df_claims['vin'].head())\nelse:\n    print(\"‚ùå vin column still missing\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Join Claims with Image_Claims_Analysis\nclaims_images = pd.merge(df_claims, dfs[\"Image_Claims_Analysis\"], on=\"claim_id\", how=\"left\")\nprint(\"Claims with image data:\", claims_images[\"image_uri\"].notnull().sum())\n\n# Join Claims with Policies and Vehicles\n# Method 1: Use left_on and right_on for explicit column mapping\n# Method 1: Use suffixes to handle conflicts\nclaims_policies = pd.merge(\n    df_claims, \n    dfs[\"Policies\"], \n    on=[\"policy_id\", \"vin\"], \n    how=\"left\"\n)\nprint(\"After merge with suffixes:\", claims_policies.columns.tolist())\n\n# Now try the second merge\nclaims_full = pd.merge(\n    claims_policies, \n    dfs[\"Vehicles\"], \n    on=\"vin\", \n    how=\"left\"\n)\nprint(\"Final columns:\", claims_full.columns.tolist())\nprint(\"Claims with full policy and vehicle info:\", claims_full.dropna(subset=[\"vin\", \"policyholder_id\"]).shape[0])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Target Column Audit","metadata":{}},{"cell_type":"code","source":"target_cols = [\n    \"airbag_deployed\",\n    \"drivable_post_accident\",\n    \"predicted_damage_severity\",\n    \"predicted_quote\",\n    \"damage_location\"\n]\n\nprint(\"\\nTarget Column Missingness:\")\nprint(df_claims[target_cols].isnull().sum())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Image Feature Profiling","metadata":{}},{"cell_type":"code","source":"df_images = dfs[\"Image_Claims_Analysis\"]\nprint(\"\\nIdentified Make Distribution:\")\ndisplay(df_images[\"identified_make\"].value_counts())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.613Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Feature Engineering Readiness","metadata":{}},{"cell_type":"code","source":"# Derived features\ndf_claims[\"claim_delay\"] = pd.to_datetime(df_claims[\"claim_filed_date\"]) - pd.to_datetime(df_claims[\"accident_date\"])\ndf_policies = dfs[\"Policies\"]\ndf_policies[\"policy_duration\"] = pd.to_datetime(df_policies[\"end_date\"]) - pd.to_datetime(df_policies[\"start_date\"])\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Summary\n\n- All five tables are structurally sound and joinable via keys.\n- Target columns in `Claims` are confirmed empty and ready for AI modeling.\n- Image-derived features offer valuable signals for damage severity and make/model.\n- Feature engineering has begun with derived time-based columns.\n\n### Next Steps\n\n- Generate embeddings using `ML.GENERATE_EMBEDDING` on image URIs\n- Train models to predict missing claim attributes\n- Use `AI.GENERATE` or BigQuery ML to populate target columns\n","metadata":{}},{"cell_type":"markdown","source":"Please ensure you specify a project id when creating the client in order to use your BigQuery account.\nTotal rows in Claims table: 70","metadata":{}},{"cell_type":"code","source":"# # ===================================================================\n# # FINAL UNIVERSAL BIGQUERY CONNECTION FOR PUBLIC KAGGLE NOTEBOOKS\n# # This method works for anyone and prevents interactive login prompts.\n# # ===================================================================\n\n# from google.colab import auth\n# from google.cloud import bigquery\n# import bigframes.pandas as bf\n\n# # The project ID where the public data resides\n# project_id = \"bqhackathonautoianalysis\" \n# location = \"us-central1\" # Specify your dataset's location\n\n# try:\n#     # --- Step 1: Authenticate the user or Kaggle environment ---\n#     # This is the key step to prevent the interactive login prompt.\n#     # It tells BigFrames and other Google Cloud libraries to use the \n#     # credentials of the environment (your user account or the public user's).\n#     auth.authenticate_user()\n#     print(\"‚úÖ Authentication successful.\")\n\n#     # --- Step 2: Initialize clients for google-cloud-bigquery and BigFrames ---\n    \n#     # Initialize the standard BigQuery client\n#     client = bigquery.Client(project=project_id)\n    \n#     # Initialize the BigFrames session\n#     bf.options.bigquery.project = project_id\n#     bf.options.bigquery.location = location\n    \n#     # (Optional but good practice) Initialize the session explicitly after auth\n#     bf.get_global_session()\n    \n#     # --- Step 3: Test Connection ---\n#     test_query = f\"\"\"\n#     SELECT COUNT(*) as total_rows \n#     FROM `{project_id}.autoAnalysis_Dataset.Claims`\n#     LIMIT 1\n#     \"\"\"\n    \n#     result = client.query(test_query).to_dataframe()\n#     print(f\"üéâ SUCCESS! Connected to public dataset.\")\n#     print(f\"Total rows in the public Claims table: {result['total_rows'].iloc[0]}\")\n    \n#     print(\"\\n‚úÖ You can now run your queries using the 'client' object for standard BigQuery...\")\n#     print(\"\\n‚úÖ ...and use BigFrames functions for large-scale data manipulation.\")\n\n# except Exception as e:\n#     print(f\"‚ùå Connection or Authentication failed.\")\n#     print(f\"   Error: {e}\")\n#     print(\"\\nTroubleshooting:\")\n#     print(\"1. Ensure this notebook has internet access enabled in Kaggle settings.\")\n#     print(\"2. Verify that the 'bqhackathonautoianalysis.autoAnalysis_Dataset' is public.\")\n\n# # ===================================================================","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"markdown","source":"Phase 1: BigFrame Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Use BigFrames instead of creating intermediate tables\nimport bigframes.pandas as bf\n\n# Load all data into BigFrames\nclaims = bf.read_gbq(\"bqhackathonautoianalysis.autoAnalysis_Dataset.Claims\")\nimages = bf.read_gbq(\"bqhackathonautoianalysis.autoAnalysis_Dataset.Image_Claims_Analysis\")\nvehicles = bf.read_gbq(\"bqhackathonautoianalysis.autoAnalysis_Dataset.Vehicles\")\n\n# Join without creating tables\nmaster_df = claims.merge(images, on=\"claim_id\").merge(vehicles, on=\"vin\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Analyzing Severity of Damage and Part of Car Impacted by Damage","metadata":{}},{"cell_type":"code","source":"import bigframes.pandas as bf\nfrom bigframes.ml.llm import GeminiTextGenerator\n\n# ==============================================================================\n# --- Session Management (CRITICAL FIX) ---\n# ==============================================================================\n# Close any previously active session to allow settings to be changed.\n# This makes the entire cell re-runnable.\ntry:\n    bf.close_session()\nexcept Exception:\n    pass # Fails silently if no session is active, which is fine.\n\n# Now, set the project for the new session. This is the correct way.\nbf.options.bigquery.project = \"bqhackathonautoianalysis\"\n\n# bf.options.bigquery.project = \"bqhackathonautoianalysis\"\n\n# 1. Load the raw images table\nraw_images = bf.read_gbq(\"bqhackathonautoianalysis.autoAnalysis_Dataset.claim_images_raw\")\n\n# 2. Create analysis prompt\nraw_images[\"analysis_prompt\"] = (\n    \"You are an AI claims inspector. Analyze the given vehicle accident image. \"\n    \"Return structured text with:\\n\"\n    \"Full response: <your description>\\n\"\n    \"Damage type: <scratch/dent/etc>\\n\"\n    \"Damage severity: <low/medium/high>\\n\"\n    \"Confidence score: <0-100>\\n\\n\"\n    \"Image URI: \" + raw_images[\"uri\"]\n)\n\n# 3. Run Gemini model safely\ngenerator = GeminiTextGenerator()\n\n# üëá This gives a new DataFrame with multiple cols, not a Series\nai_output = generator.predict(raw_images[\"analysis_prompt\"])\n\n# 4. Inspect what Gemini returned\nprint(ai_output.head())   # check columns\n\n# 5. Assume the text is in 'ml_generate_text_result' column\nraw_images[\"final_response\"] = ai_output[\"ml_generate_text_llm_result\"]\n\n# 6. Extract structured fields from final_response\n# Instead of .apply(lambda x: f\"Extract the damage type from this text: {x}\")\nraw_images[\"damage_type_prompt\"] = \"Extract the damage type from this text: \" + raw_images[\"final_response\"]\nraw_images[\"damage_severity_prompt\"] = \"Extract the damage severity from this text: \" + raw_images[\"final_response\"]\nraw_images[\"confidence_prompt\"] = \"Provide a confidence score (0-1) for this analysis: \" + raw_images[\"final_response\"]\n\n# Now pass these directly into Gemini\nextractor = GeminiTextGenerator()\n# Run Gemini and select only the text output\ndamage_type_output = extractor.predict(raw_images[\"damage_type_prompt\"])\nraw_images[\"identified_damage_type\"] = damage_type_output[\"ml_generate_text_llm_result\"]\n\nseverity_output = extractor.predict(raw_images[\"damage_severity_prompt\"])\nraw_images[\"identified_damage_severity\"] = severity_output[\"ml_generate_text_llm_result\"]\n\nconfidence_output = extractor.predict(raw_images[\"confidence_prompt\"])\nraw_images[\"confidence_score\"] = confidence_output[\"ml_generate_text_llm_result\"]\n\n# # 7. Use a regular expression to extract the first number from the text.\n# # This pattern finds integers (e.g., 90) or decimals (e.g., 0.9, 0.75).\n# # The parentheses () create a \"capture group\" for .str.extract().\n# regex_pattern = r'(\\d*\\.?\\d+)'\n\n# # .str.extract() returns a DataFrame with one column per capture group.\n# # We select the first (and only) column with [0].\n# extracted_score_str = raw_images[\"confidence_score\"].str.extract(regex_pattern)[0]\n\n# # 8. Convert the extracted string to a numeric type (float).\n# numeric_score = extracted_score_str.astype(float)\n\n# # 9. Normalize the score. If the number is > 1 (e.g., 90), divide it by 100.\n# # Otherwise, keep it as is (e.g., 0.9).\n# # .where() is an efficient way to apply this conditional logic.\n# normalized_score = numeric_score.where(numeric_score <= 1, numeric_score / 100)\n\n# # 10. Assign the clean, normalized score to the final column.\n# raw_images[\"confidence_score\"] = normalized_score\n\n# # Optional: You can now drop the temporary text column if you no longer need it\n# if 'confidence_score_text' in raw_images.columns:\n#     raw_images = raw_images.drop(columns=['confidence_score_text'])\n\nprint(\"--- Starting Enrichment: Adding Vehicle Make and Model ---\")\n\n# 11. Load the Image_Claims_Analysis table\n# We only need the key ('image_uri') and the data we want to add.\n# This is more efficient than loading the whole table.\ncolumns_to_fetch = [ 'claim_id', 'image_uri', 'identified_make', 'identified_model']\nimage_analysis_data = bf.read_gbq(\n    \"bqhackathonautoianalysis.autoAnalysis_Dataset.Image_Claims_Analysis\",\n    columns=columns_to_fetch\n)\nprint(\"\\nSuccessfully loaded make/model data. Columns:\", image_analysis_data.columns)\n\n# 12. Merge the two DataFrames\n# This performs a LEFT JOIN, keeping all records from `raw_images` and adding\n# matching make/model data from `image_analysis_data`.\nenriched_images = raw_images.merge(\n    image_analysis_data,\n    left_on='uri',         # Key in the original DataFrame\n    right_on='image_uri',    # Key in the new data\n    how='left'             # Keep all rows from the left DataFrame\n)\n\n# 13. Clean up the final DataFrame\n# The merge leaves a redundant 'image_uri' column, which we can drop.\nif 'image_uri' in enriched_images.columns:\n    enriched_images = enriched_images.drop(columns=['image_uri'])\n\n\n# --- Verification ---\nprint(\"\\n--- Final DataFrame Columns After Merge ---\")\nprint(enriched_images.columns)\n\nprint(\"\\n--- Sample of Final Enriched Data ---\")\n# Displaying the key columns plus the newly added ones to verify the merge\nprint(enriched_images[[\n    'uri', \n    'identified_make', \n    'identified_model',\n    'identified_damage_type', \n    'identified_damage_severity', \n    'confidence_score'\n]].head())\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Select the key columns and take 5 random rows\npreview_df = enriched_images[\n    [\"identified_make\", \"identified_model\", \"identified_damage_type\", \"identified_damage_severity\"\n    ]].to_pandas().sample(5, random_state=42)\n\n# Display as a styled HTML table\npreview_df.style.set_table_styles(\n    [\n        {\"selector\": \"th\", \"props\": [(\"background-color\", \"#f4f4f4\"), (\"font-weight\", \"bold\")]},\n        {\"selector\": \"td\", \"props\": [(\"padding\", \"8px\"), (\"border\", \"1px solid #ddd\")]}\n    ]\n).set_caption(\"Sample of Predicted Car Damage Analysis\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ==============================================================================\n## Phase 2: Predicting Key Claim Metrics with Generative AI ---\n## This cell directly follows the previous one and uses the 'enriched_images' DataFrame.\n## Our goal is to predict: damage_location, airbag_deployed, drivable_post_accident,\n## and predicted_quote. We will also clean up the predicted_damage_severity.\n## ==============================================================================","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# --- Phase 2: Predicting Key Claim Metrics (Presentation Ready v3) ---\n# This version fixes the KeyError and produces a polished output.\n# ==============================================================================\nimport bigframes.pandas as bf\nimport warnings\nimport logging\nimport bigframes # Import the top-level package to access exceptions\n\n# Suppress PreviewWarning and other informational logs for a clean output\nwarnings.filterwarnings(\"ignore\", category=bigframes.exceptions.PreviewWarning)\nlogging.basicConfig(level=logging.WARNING)\n\nprint(\"--- Phase 2: Starting Prediction of Key Claim Metrics ---\")\n\n# Initialize the GeminiTextGenerator model\nextractor = GeminiTextGenerator()\n\n# --- Step 1: Predict Damage Location ---\nenriched_images[\"damage_location_prompt\"] = \"You are an expert vehicle claims adjuster. Based on the following damage description, identify the primary location of the damage (e.g., 'Front Bumper'). Return ONLY the location as a short phrase.\\n\\nDescription: \" + enriched_images[\"final_response\"]\ndamage_location_output = extractor.predict(enriched_images[\"damage_location_prompt\"])\nenriched_images[\"damage_location\"] = damage_location_output[\"ml_generate_text_llm_result\"]\nprint(\"‚úÖ Predicted Damage Location.\")\n\n# --- Step 2: Predict Airbag & Drivability ---\nenriched_images[\"airbag_prompt\"] = \"Given the accident description for a \" + enriched_images[\"identified_make\"] + \" \" + enriched_images[\"identified_model\"] + \", is it likely airbags deployed? Answer ONLY with 'True' or 'False'.\\n\\nDescription: \" + enriched_images[\"final_response\"]\nenriched_images[\"drivable_prompt\"] = \"Given the accident description, is the vehicle likely drivable? Answer ONLY with 'True' or 'False'.\\n\\nDescription: \" + enriched_images[\"final_response\"]\nairbag_output = extractor.predict(enriched_images[\"airbag_prompt\"])\nenriched_images[\"airbag_deployed\"] = airbag_output[\"ml_generate_text_llm_result\"].str.contains(\"True\", case=False)\ndrivable_output = extractor.predict(enriched_images[\"drivable_prompt\"])\nenriched_images[\"drivable_post_accident\"] = drivable_output[\"ml_generate_text_llm_result\"].str.contains(\"True\", case=False)\nprint(\"‚úÖ Predicted Airbag Deployment and Drivability.\")\n\n# --- Step 3: Improved Severity Prediction and Parsing ---\nenriched_images[\"refined_severity_prompt\"] = (\n    \"Analyze the damage description below. Classify the severity as ONLY one of the following words: 'Low', 'Medium', or 'High'.\\n\\n\"\n    \"Description: \" + enriched_images[\"final_response\"]\n)\nseverity_output = extractor.predict(enriched_images[\"refined_severity_prompt\"])\nseverity_text = severity_output[\"ml_generate_text_llm_result\"]\n\n# Robustly parse the output to get clean labels\nregex_pattern = r'(?i)(Low|Medium|High)'\nextracted_severity_df = severity_text.str.extract(regex_pattern)\n# CORRECTED: Access the column using the string '0', not the integer 0.\nclean_severity = extracted_severity_df['0'].str.capitalize().fillna('Medium')\nenriched_images[\"predicted_damage_severity\"] = clean_severity\nprint(\"‚úÖ Refined and Parsed Predicted Damage Severity.\")\n\n# --- Step 4: Predict Repair Quote ---\nenriched_images[\"quote_prompt\"] = \"You are an expert auto repair estimator. For a '\" + enriched_images[\"identified_make\"] + \" \" + enriched_images[\"identified_model\"] + \"' with '\" + enriched_images[\"predicted_damage_severity\"] + \"' damage, estimate the repair cost in USD. Return ONLY a single number.\\n\\nDescription: \" + enriched_images[\"final_response\"]\nquote_output = extractor.predict(enriched_images[\"quote_prompt\"])\nenriched_images[\"predicted_quote_text\"] = quote_output[\"ml_generate_text_llm_result\"]\n\n# Parse the numeric quote value\nregex_pattern_quote = r'(\\d*\\.?\\d+)'\nextracted_df_quote = enriched_images[\"predicted_quote_text\"].str.extract(regex_pattern_quote)\n# CORRECTED: Access the column using the string '0', not the integer 0.\nextracted_quote_str = extracted_df_quote['0'].fillna('0')\nnumeric_quote = extracted_quote_str.astype(float)\nenriched_images[\"predicted_quote\"] = numeric_quote\nprint(\"‚úÖ Predicted and Parsed Repair Quote.\")\n\n# --- Step 5: Create the Final DataFrame for Presentation ---\nfinal_preview_df = enriched_images[[\n    'claim_id',\n    'identified_make',\n    'identified_model',\n    'damage_location',\n    'identified_damage_type',\n    'predicted_damage_severity',\n    'airbag_deployed',\n    'drivable_post_accident',\n    'predicted_quote'\n]]\n\n# --- FINAL, CLEAN OUTPUTS FOR JUDGES ---\n\n# Output 1: Display the final, parsed severity distribution\nprint(\"\\n--- Final AI-Predicted Severity Distribution ---\")\nseverity_counts = enriched_images[\"predicted_damage_severity\"].value_counts().to_pandas()\nprint(severity_counts)\n\n# Output 2: Display a sample of the final, enriched table\nprint(\"\\n--- Sample of Final Enriched Claims Data ---\")\ndisplay(final_preview_df.head(5))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Executive Triage Dashboard Table","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# --- Final Presentation: Polished Executive Triage Table (Top 10 Entries) ---\n# This cell takes the final predictions and formats them into a clean,\n# professional HTML table exactly as requested.\n# ==============================================================================\nimport pandas as pd # Ensure pandas is imported for styling\n\n# Fetch the top 10 rows from BigFrames into a standard pandas DataFrame.\n# Using .head(10).to_pandas() is efficient as it only brings a small sample into memory.\nfinal_pandas_df = final_preview_df.head(10).to_pandas()\n\n# Define the color-coding function for the severity column.\ndef style_severity(severity):\n    if severity is None:\n        return ''\n    # The .strip() and .lower() ensure robust matching (e.g., \" High \" becomes \"high\")\n    severity = str(severity).strip().lower()\n    if 'high' in severity:\n        return 'background-color: #ffcccc; color: #a60000; font-weight: bold;' # Red\n    elif 'medium' in severity:\n        return 'background-color: #ffebcc; color: #b85c00;' # Orange\n    elif 'low' in severity:\n        return 'background-color: #d6f5d6; color: #006400;' # Green\n    else:\n        return ''\n\n# Apply the full set of styles to create the final presentation table.\nstyled_df = final_pandas_df.style \\\n    .set_caption(\"Live Triage: AI-Predicted Claim Attributes (Top 10 Sample)\") \\\n    .set_table_styles([\n        {'selector': 'th', 'props': [\n            ('background-color', '#f2f2f2'),\n            ('font-weight', 'bold'),\n            ('text-align', 'left'),\n            ('padding', '8px'),\n            ('border', '1px solid #ddd')\n        ]},\n        {'selector': 'td', 'props': [\n            ('padding', '8px'),\n            ('border', '1px solid #ddd'),\n            ('text-align', 'left') # Default alignment for text\n        ]},\n        {'selector': 'caption', 'props': [\n            ('color', 'black'),\n            ('font-size', '1.3em'),\n            ('font-weight', 'bold'),\n            ('margin-bottom', '10px')\n        ]}\n    ]) \\\n    .format({\n        \"predicted_quote\": \"${:,.2f}\",  # Format as currency\n        \"airbag_deployed\": lambda x: '‚úîÔ∏è Yes' if x else '‚ùå No',\n        \"drivable_post_accident\": lambda x: '‚úîÔ∏è Yes' if x else '‚ùå No'\n    }) \\\n    .apply(lambda s: s.map(style_severity), subset=['predicted_damage_severity']) \\\n    .set_properties(**{'text-align': 'center'}, subset=['airbag_deployed', 'drivable_post_accident', 'predicted_damage_severity']) \\\n    .set_properties(**{'text-align': 'right'}, subset=['predicted_quote']) \\\n    .hide(axis='index')\n\n# Display the final, styled table.\ndisplay(styled_df)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ==============================================================================\n# --- Validation & Summary: Final Severity Distribution (CORRECTED) ---\n# This cell provides a high-level overview of the final prediction results,\n# proving the success of our data refinement.\n# ==============================================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Ensure a professional plot style\nsns.set_style(\"whitegrid\")\n\n# --- ROBUST FIX 1: NORMALIZE THE DATA ---\n# Convert the generated severity to lowercase and strip any extra spaces.\n# This makes the data consistent and prevents errors from minor AI variations.\nfinal_preview_df[\"predicted_damage_severity\"] = final_preview_df[\"predicted_damage_severity\"].str.lower().str.strip()\n\n# Get the final counts of each severity level from the BigFrames DataFrame\nfinal_severity_counts = final_preview_df[\"predicted_damage_severity\"].value_counts().to_pandas()\n\n# --- Part 1: The Raw Numbers (For the Report) ---\nprint(\"--- Final Distribution of Predicted Damage Severity ---\")\nprint(\"After refining the prompts and robustly parsing the output, the final counts are:\")\nprint(final_severity_counts)\nprint(\"\\n\" + \"=\"*50 + \"\\n\") # Visual separator\n\n# --- Part 2: The Executive Visualization ---\n# Create a bar chart to visually represent the distribution\nplt.figure(figsize=(10, 6))\n\n# --- ROBUST FIX 2: UPDATE INDEX AND PALETTE TO MATCH NORMALIZED DATA ---\n# Use lowercase for the index and palette keys to match the cleaned data.\nordered_index = pd.Index(['low', 'medium', 'high']).intersection(final_severity_counts.index)\n\n# Ensure the palette keys are also lowercase\npalette = {'low': '#90ee90', 'medium': '#ffcc99', 'high': '#ff9999'}\n\n# Check if there is anything to plot to avoid the error completely\nif not ordered_index.empty:\n    sns.barplot(\n        x=ordered_index,\n        y=final_severity_counts.loc[ordered_index],\n        palette=palette,\n        edgecolor='black'\n    )\n    plt.title('Final Count of Claims by AI-Predicted Severity', fontsize=16, fontweight='bold')\n    plt.xlabel('Predicted Damage Severity', fontsize=12)\n    plt.ylabel('Number of Claims', fontsize=12)\n    \n    # Add data labels on top of the bars for clarity\n    for index, value in enumerate(final_severity_counts.loc[ordered_index]):\n        plt.text(index, value + 0.5, str(value), ha='center', va='bottom', fontsize=12, fontweight='bold')\n    \n    plt.show()\nelse:\n    print(\"‚ö†Ô∏è No data available to plot for severity distribution. The `ordered_index` is empty.\")\n# # ==============================================================================\n# # --- Validation & Summary: Final Severity Distribution ---\n# # This cell provides a high-level overview of the final prediction results,\n# # proving the success of our data refinement.\n# # ==============================================================================\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# # Ensure a professional plot style\n# sns.set_style(\"whitegrid\")\n\n# # Get the final counts of each severity level from the BigFrames DataFrame\n# final_severity_counts = final_preview_df[\"predicted_damage_severity\"].value_counts().to_pandas()\n\n# # --- Part 1: The Raw Numbers (For the Report) ---\n# print(\"--- Final Distribution of Predicted Damage Severity ---\")\n# print(\"After refining the prompts and robustly parsing the output, the final counts are:\")\n# print(final_severity_counts)\n# print(\"\\n\" + \"=\"*50 + \"\\n\") # Visual separator\n\n# # --- Part 2: The Executive Visualization ---\n# # Create a bar chart to visually represent the distribution\n# plt.figure(figsize=(10, 6))\n# # Order the index so the bar chart is logically sorted (Low, Medium, High)\n# ordered_index = pd.Index(['Low', 'Medium', 'High']).intersection(final_severity_counts.index)\n\n# sns.barplot(\n#     x=ordered_index,\n#     y=final_severity_counts.loc[ordered_index],\n#     palette={'Low': '#90ee90', 'Medium': '#ffcc99', 'High': '#ff9999'}, # Softer colors\n#     edgecolor='black'\n# )\n# plt.title('Final Count of Claims by AI-Predicted Severity', fontsize=16, fontweight='bold')\n# plt.xlabel('Predicted Damage Severity', fontsize=12)\n# plt.ylabel('Number of Claims', fontsize=12)\n# # Add data labels on top of the bars for clarity\n# for index, value in enumerate(final_severity_counts.loc[ordered_index]):\n#     plt.text(index, value + 0.5, str(value), ha='center', va='bottom', fontsize=12, fontweight='bold')\n# plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Styled Executive Triage Table**\nThis cell takes the final predictions and formats them for clear business insights.","metadata":{}},{"cell_type":"markdown","source":"Financial Impact Analysis - Average Repair Cost","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# --- Stakeholder View 1: Financial Impact Analysis (Presentation Ready v2) ---\n# This version corrects the AttributeError and enhances readability.\n# ==============================================================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.ticker import StrMethodFormatter\n\n# Set a professional plot style\nsns.set_style(\"whitegrid\")\n\n# --- Data Cleaning for Consistent Plotting ---\n# CORRECTED: Use .str.capitalize() which is supported by BigFrames.\n# For single words like 'Low' or 'High', it works the same as .title().\nenriched_images[\"predicted_damage_severity\"] = enriched_images[\"predicted_damage_severity\"].str.strip().str.capitalize()\nenriched_images[\"identified_make\"] = enriched_images[\"identified_make\"].str.strip().str.capitalize()\n\n\n# --- Analysis 1: Average Quote by Damage Severity ---\n# Group by the now-clean severity column\navg_quote_by_severity = enriched_images.groupby(\"predicted_damage_severity\")[\"predicted_quote\"].mean().to_pandas().sort_values()\n\n# Create the plot using matplotlib's axes for more control\nfig, ax = plt.subplots(figsize=(10, 6))\n# Ensure the order uses the same capitalization\nsns.barplot(x=avg_quote_by_severity.index, y=avg_quote_by_severity.values, palette=\"Reds\", ax=ax, order=['Low', 'Medium', 'High'])\n\n# Add clear data labels on top of each bar\nax.bar_label(ax.containers[0], fmt='${:,.0f}', fontsize=12, fontweight='bold', padding=3)\n\n# Set well-defined titles and labels\nax.set_title('Average Predicted Repair Quote by Damage Severity', fontsize=16, fontweight='bold')\nax.set_xlabel('AI-Predicted Damage Severity', fontsize=12)\nax.set_ylabel('Average Quote (USD)', fontsize=12)\nax.yaxis.set_major_formatter(StrMethodFormatter('${x:,.0f}')) # Format y-axis as currency\n\n# Adjust layout to prevent any overlap\nplt.tight_layout()\nplt.show()\n\n\n# --- Analysis 2: Average Quote by Vehicle Make (Top 10) ---\n# Group by the now-clean make column\navg_quote_by_make = enriched_images.groupby(\"identified_make\")[\"predicted_quote\"].mean().to_pandas().nlargest(10).sort_values()\n\n# Create the horizontal bar plot\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.barplot(x=avg_quote_by_make.values, y=avg_quote_by_make.index, palette=\"Blues_r\", orient='h', ax=ax)\n\n# Add clear data labels to the right of each bar\nax.bar_label(ax.containers[0], fmt=' ${:,.0f}', fontsize=11, fontweight='bold', padding=5)\n\n# Set well-defined titles and labels\nax.set_title('Top 10 Most Expensive Vehicle Makes to Repair', fontsize=16, fontweight='bold')\nax.set_xlabel('Average Quote (USD)', fontsize=12)\nax.set_ylabel('AI-Identified Vehicle Make', fontsize=12)\nax.xaxis.set_major_formatter(StrMethodFormatter('${x:,.0f}')) # Format x-axis as currency\n\n# Ensure the x-axis has some padding so labels don't get cut off\nax.set_xlim(right=avg_quote_by_make.max() * 1.15) \n\n# Adjust layout to prevent any overlap\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Operational Triage Analysis - Damage Hotspots","metadata":{}},{"cell_type":"code","source":"# ==============================================================================\n# --- Stakeholder View 2: Operational Triage - Damage Hotspots ---\n# ==============================================================================\n\n# Calculate the frequency of each damage location\ndamage_location_counts = enriched_images[\"damage_location\"].value_counts().to_pandas().nlargest(10)\n\nplt.figure(figsize=(12, 7))\nlocation_plot = sns.barplot(x=damage_location_counts.values, y=damage_location_counts.index, palette=\"viridis\", orient='h')\nplt.title('Top 10 Most Common Damage Locations', fontsize=16, fontweight='bold')\nplt.xlabel('Number of Claims', fontsize=12)\nplt.ylabel('Damage Location', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-22T22:40:20.615Z"}},"outputs":[],"execution_count":null}]}