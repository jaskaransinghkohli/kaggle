

Project Title: Auto-Claim Genius: An AI-Powered Insurance Claims Resolution Engine Problem Statement The auto insurance industry is inundated with a complex mix of structured and unstructured data, from policy details and vehicle specifications to raw accident images and textual descriptions. The traditional process of manually reviewing this data to assess damage, determine fault, and estimate repair costs is notoriously slow, inconsistent, and resource-intensive. This inefficiency creates a significant operational bottleneck, leading to delayed resolutions, increased costs, and a frustrating customer experience. The core problem is not a lack of data, but the inability to unlock and synthesize insights from these varied formats at scale. Impact Statement Auto-Claim Genius directly addresses this challenge by creating an end-to-end, AI-driven workflow within Google BigQuery. Our solution transforms the claims process from a manual, multi-day task into a streamlined, automated analysis. The material impact is a significant reduction in claim cycle times, a decrease in operational overhead, and a dramatic improvement in the consistency and accuracy of initial damage assessments. This allows claims adjusters to focus their expertise on the most complex cases, leading to faster payouts, reduced fraud, and ultimately, higher customer satisfaction and retention. Solution Overview & Technical Walkthrough Auto-Claim Genius is a working prototype that demonstrates how BigQuery's native AI capabilities can build an intelligent business application directly on top of a data warehouse. Our solution follows a three-phase process to turn raw, mixed-format data into polished, actionable business intelligence. Phase 1: Data Preparation & Multimodal Enrichment This phase addresses the challenge of combining disparate data sources into a single, analysis-ready master table. We heavily utilized BigFrames, the Python API for BigQuery, to perform large-scale data manipulation without moving data out of the warehouse. Unified Data Loading: We began by loading our structured tables (Claims, Policies, Vehicles, Policyholders) and unstructured data sources (claim_images_raw, Image_Claims_Analysis) into BigFrames DataFrames. Multimodal Fusion: We then performed a series of joins to create a master feature table. This process seamlessly combines structured data (e.g., accident_type, vehicle_age) with unstructured data (the text description of accident images), a core tenet of the Multimodal Pioneer approach. Feature Engineering: We derived new, valuable features directly in BigQuery, such as days_to_file_claim and composite_risk_score, to provide richer context for our AI models. Phase 2: AI-Powered Prediction of Key Claim Attributes This is the heart of our solution and a direct implementation of the AI Architect approach. The goal was to use generative AI to intelligently predict and fill in the five critical, but often missing, columns in our claims dataset. Contextual Prompting: For each claim, we dynamically constructed a rich, contextual prompt. This prompt provided the Gemini model with a comprehensive summary of the incident, including structured data points and the unstructured text analysis of the accident image. Generative Prediction with Gemini: We used bigframes.ml.llm.GeminiTextGenerator to analyze this prompt and generate predictions for the five target fields: airbag_deployed (True/False) drivable_post_accident (True/False) predicted_damage_severity (Low, Medium, or High) predicted_quote (A specific USD amount) damage_location (e.g., Front Bumper) Robust Parsing: To ensure data quality, we applied robust parsing techniques using regular expressions (regex) to extract the structured information from the model's free-form text output and populate our final DataFrame. code Python
--- Step 3 (REFINED): Improved Severity Prediction and Parsing ---

enriched_images["refined_severity_prompt"] = ( "Analyze the damage description below...classify the severity as ONLY " "one of the following words: 'Low', 'Medium', or 'High'.\n\n" "Description: " + enriched_images["final_response"] ) severity_output = extractor.predict(enriched_images["refined_severity_prompt"]) severity_text = severity_output["ml_generate_text_llm_result"]
Robustly parse the output to get clean labels

regex_pattern = r'(?i)(Low|Medium|High)' extracted_severity_df = severity_text.str.extract(regex_pattern) clean_severity = extracted_severity_df['0'].str.capitalize().fillna('Medium') enriched_images["predicted_damage_severity"] = clean_severity Phase 3: Generating Actionable Business Insights The final phase focuses on translating our AI-enriched data into polished, easy-to-understand visualizations and tables for different business stakeholders. The Executive Triage Dashboard: We created a final, styled HTML table that serves as a live triage dashboard. It uses clear visual cues like color-coding for severity and icons for boolean values, allowing a claims manager to instantly identify high-priority cases. Financial Impact Analysis: By aggregating the AI-predicted repair quotes, we generated charts showing the average cost by damage severity and by vehicle make. This provides the finance department with crucial data for risk modeling and forecasting. Operational Triage Analysis: We visualized the most common damage locations, providing the operations team with insights that can inform their repair network strategy and parts inventory. Competition Approaches Addressed Our project successfully implements two of the three proposed approaches. Approach 1: The AI Architect üß† Your Mission: Use BigQuery's built-in generative AI to architect intelligent business applications and workflows. Our solution is a prime example of this approach. We didn't just generate text; we architected an end-to-end workflow that ingests raw data, uses bigframes.ml.llm.GeminiTextGenerator to predict multiple structured fields, and outputs a complete, actionable dataset and corresponding business intelligence dashboards. This directly solves a complex business problem by generating structured, summarized, and predictive information within the data warehouse. Approach 3: The Multimodal Pioneer üñºÔ∏è Your Mission: Break the barriers between structured and unstructured data using BigQuery's multimodal capabilities. We fully embraced this mission by building our AI prompts on a fusion of data types. Our BigFrames Multimodal DataFrame (enriched_images) combined structured columns like accident_type and vehicle_age with unstructured data derived from images (final_response). This combination allowed the Gemini model to make far more accurate and context-aware predictions than would have been possible with either data type in isolation. Tools & Technologies Used Google BigQuery: The core data warehouse for storing and processing all claims data. BigFrames API: The primary tool for Python-based, scalable data manipulation and AI integration, allowing us to work with terabytes of data using a familiar pandas-like syntax. Gemini Models (via GeminiTextGenerator): The advanced generative AI engine used for both image analysis and the prediction of structured claim attributes. Python Libraries: Pandas, Matplotlib, and Seaborn were used within the Kaggle notebook for final-stage data styling and visualization. Conclusion & Future Directions Auto-Claim Genius successfully demonstrates that BigQuery AI is not just a set of functions, but a powerful platform for building complete, end-to-end business solutions. By integrating generative and multimodal capabilities directly into the data warehouse, we have created a prototype that dramatically accelerates and enhances the auto insurance claims process. For future development, the next logical step would be to incorporate Approach 2: The Semantic Detective. By using ML.GENERATE_EMBEDDING on the accident descriptions and VECTOR_SEARCH, the system could instantly find historically similar claims, suggest proven repair solutions, and further improve the accuracy of cost predictions.
